
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Developer's Perception</title>
  <meta name="author" content="Nikolaj Kaare NÃ¸rskov">

  
  <meta name="description" content="Just testing out the octopress blogging engine. I am considering moving away from blogger, mostly to enable me to write in markdown (I am not a fan &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://elgsdyret.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Developer's Perception" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Developer's Perception</a></h1>
  
    <h2>Odd thoughts from a developer.</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:elgsdyret.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/27/porting-to-octopress/">Porting to Octopress</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-27T19:16:00+02:00" pubdate data-updated="true">May 27<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Just  testing out the octopress blogging engine. I am considering moving away from blogger, mostly to enable me to write in markdown (I am not a fan of editing in the browser) and to get the control of whats going one.</p>

<p>Sofar it has been easy enough to get working, but I imagine it will require quite a bit of work to set it up completely as my main blogging outlet.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/25/code-generation-in-net/">Code Generation in .NET</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-25T12:39:00+02:00" pubdate data-updated="true">May 25<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<p>Code generation has over time turned into one of my pet peeves when working in .NET (although most of it will apply to similar platforms like JAVA). Let me be very clear from the beginning of this post. I am advocating that you should use extreme caution before even considering using code generation to solve whatever real or perceived problems you might find it useful for. I have yet to see an implementation that has not caused extra problems. That does not necessarily mean that it cannot be valuable tool, but please take a step back and think before continuing down that path.</p> <blockquote>  <p>This is the longest blog post I have yet written. It contains no code, just ranting, and hopefully some insights.</p></blockquote> <h3>Possible Motivation</h3> <p>Code generation is typically introduced to:</p> <ul><li>remove duplication.</li><li>reduce tedious coding.</li><li>enforce security measures (authentication and authorization).</li><li>enforce consistent handling of resources such as database connections and transactions.</li><li>apply cross cutting concerns such as logging or caching.</li></ul> <p>And probably a number of other reasons. Basically, anything that seems hard to do in a nice way in the language and framework you are currently working with. Most of these things can be handled by using more light weight measures, using more simple and well known designs based on patterns. </p> <p>Regarding tedious coding it would be wise to step back and consider why there is so much tedious coding? If the number of lines of code compared to the functionality it provides is so high that you consider using code generation, I would put it to you that your design is not very good. Basically, you are trying to hammer a square peg into a round hole, and instead of seeing the error of that you just get a bigger hammer (called code generation). </p> <h3>How to Determine what to Generate</h3> <p>Usually, you would determine what to generate based on an external resource (like XML files), examining the existing code structure using the reflection API, or annotating the existing code somehow (probably using attributes) and then examining that using the reflection API.</p> <p>No matter how you choose to do this you are defining rules that are not clear from the context. An XML file is a very loose format and what is generated from that XML file is by no means clear to a developer looking at that XML, and it can also be very hard to determine from the code of the code generator. Similar problems arise when using the existing code structure or attributes, it is simply not very clear what rules are being applied and how the resulting code will look.</p> <p>Step back and consider the number of characters in those XML files. Now consider the number of characters of the code if you wrote it by hand in the same way the code generator does it. Now consider the number of characters for the code of the generator. Often you will find that you end up with more characters using the XML than just using the code. Then consider that XML files cannot be unit tested, the build process will be more complicated, and you will have to actually write the code generator. </p> <p>If you determine what to generate based on examining the existing code you will introduce the problem of simple code changes causing an unwanted side effect. I still recall changing the name of a parameter in a function in a model class as it was misspelled. Compilation and tests worked fine as they should. What I did not foresee was that suddenly our public API had a breaking change as it was generated from the core model. Our public SDK had suddenly also introduced this change as it was also generated from the code models. So basically all our integration partners had to change their code, or we could rollback the release. I know this is an extreme scenario and probably not something you would ponder, but there really is no limit for the ingenuity (insanity) of developers when trying to solve problems.</p> <blockquote>  <p><em>If you end up doing code generation despite all my attempts to get you to move away from it, do work dilligently on creating and maintaining documentation for you base generation format, whether it is XML based, annotations, or the structure of the code.</em> </p></blockquote> <h3>How to Actually Generate the code</h3> <p>Once the motivation is in place and you have somehow figured out how to determine what the output code should look like, it is time to actually generate some code.</p> <p>There are a number of different tools for doing this in the .NET stack, but all of them basically falls into to different categories:  + generate by code API (such as the CodeDOM)  + generate by template (such as T4 templates)</p> <p>Using code to generate code is a feasible approach, but unfortunately the APIs in .NET for this are extremely cumbersome and verbose leading to a lot of incomprehensible code. For instance the combination of CodeDOM and reflection (for reading base format) leads to some of the least readable code I have ever encountered in .NET. This basically means that it is very hard to envision the resulting code from the generator, which leads to random experimentation followed by examination of the resulting code to verify changes (if possible).</p> <p>Using a template engine is a better alternative. The templates will most likely be a raw text format with placeholders for the code that has variation. This means it is a lot easier to envision the resulting code. Usually, the placeholders should be fairly few, otherwise, the reusability is very low and the code generation should probably never have been implemented at all.</p> <blockquote>  <p><em>Use a template based engine and put as much as the generation logic in the template.</em> </p></blockquote> <p>There is an alternative where you generate the code based on a 3rd party solution, such as PostSharp. In this scenario it is the 3rd party that defines the &#8216;how to determine what to generate&#8217; and maintain most of the documentation.</p> <blockquote>  <p><em>Do not start from scratch. Search the market for generation tools that can do the bulk of the lifting for you.</em> </p></blockquote> <h3>Build Process</h3> <p>Once the code is generated there is a number of ways it can interact with the rest of the codebase:</p> <ol><li>never generate a file just build it straight into a DLL</li><li>generate a temp file as part of build and delete it afterwards</li><li>generate a temp file and try to hide it from the developers (the folder it is in is not included in the project etc.)</li><li>generate a temp file and use it in build (the build is seperate step from generation).</li><li>only generate the code on demand and check it in with the rest of the code. </li></ol> <p>The distinction between these methods can seem very narrow. The important part is whether the generated code is an artifact of the build process and how easy it is to see for the developers.</p> <p>The first 3 options basically assumes that it is not a good thing if the developer can see and modify the generated code. As if bad stuff would come from that, which it might. </p> <p>The last 2 assumes that the generated code is not directly an artifact from the build process. Item 4 is not that different from 1-3, but at least it keeps the code generation step as a seperate step from the build process. This could be a pre process step in building with Visual Studio and the actual build just picks up the file from the project.</p> <p>Item 5 is basically a templating engine. You generate something once and it is perfectly acceptable to modify it afterwards. This is just like when you add a class file in Visual Studio it will have a bit of code prefilled such as namespace, classname, and useless using statements. Similarly, with very simple commands you can generate new controllers and models in RAILS. </p> <blockquote>  <p><em>Make sure the build process is not made more complicated (and slower) due to the code generation. Ensure that the code generation is an optional step that comes before the build. Consider only generating once and keeping the files in source control if feasible.</em></p></blockquote> <h3>Examples</h3> <p>I am just going to run through some of the examples of code generation I have encountered sofar. One is bad, but ultimately not that harmful, two have been extremely costly, and one is maybe ok.</p> <h4>Re-use of Internal Model in Other Services</h4> <p>The first example of a custom code generator I encountered was used to share models between a number of different services. Basically, the team had decided to go for a SOA design, but not really unstood how to implement it. It was a relatively simple business application consisting of a an ASP.NET webforms site and no less than 12 SOAP based web services. </p> <p>We eventually came to the conclussion that probably 3 services would have been just about right, as the services depended on each other to a large degree. The sheer work of maintaining a model that belonged in service A, but was used in service B, service C, and the website quickly became a pain with 12 services. Thus, a code generator had been build to generate these models, making this an example of bad design driving the creation of the code generator.</p> <p>Luckily, the simplicity of the generated classes, the ease with which they could be extended, and the simplicity of the code generator itself ensured that it was only slightly cumbersome to work with.</p> <h4>Custom ORM NHibernate Wrapper</h4> <p>I could write a series of blog posts on this example alone, but basically this backend system was designed by someone that considered code generation his speciality and consequently applied it to everything possible.</p> <p>Combine this with a desire to build a custom ORM and you get one of the most convoluted systems I have seen. Basically, more or less the entire backend system was generated from XML. The idea of the homemade ORM was eventually dropped, but its basic API was then used to wrapped NHibernate. So as a developer you are basically stuck with a homemade XML format for queries and entities, which was the used to generate mapping and queries for NHibernate. Due to the complexity of such a system the queries and the mapping are highly ineffective. </p> <p>The worst part was how hard it was to actually write any kind off meaningful code for the system. The generated entities and queries (called views) were hidden and impossible to extend, actually, the only intended way to implement business logic was static methods were everything was passed as parameters. Some of the hacks developers had implemented on top of this system to be able to deliver features only made it worse.</p> <p>To top off the problems with this code generation it was full of bugs and very hard to modify. Part of the code generator was even code generated.</p> <p>Possibly the worst design I have ever seen. For a relatively simple business domain and equally simple functionality.</p> <h4>Service Layer Method Generator</h4> <p>This is another example of a very complex code generation system. I cannot be completely certain of the motivation for this code generation system, but my guess is that it is yet another example of a bad design that caused a lot of manual work.</p> <p>The core of the system is a number of entities, build by hand and mapped with NHibernate. The entities have specific queries as static method in an Active Record style. This design in itself is not that bad. One could argue back and forth of the merits of Active Record compared to the Repository pattern, but at least it is a well known and tried pattern.</p> <p>Based on the methods, properties, and certain custom attributes of these entities a number of things were code generated (which was not documented ofcourse):</p> <ul><li>A service layer directly exposing all the public methods of the webservice. In this service layer certain cross cutting concerns was added, such as connection and transaction handling, exception handling, and security checks.</li><li>A number of classes that was build into a .NET based SDK.</li></ul> <p>The idea behind the .NET based SDK was that it should work in a RPC style, and it contained both proxy objects and data objects directly generated based on the data retrieved from the core entities. In itself exposing internal implementation details in this way is never a good idea. As a direct consequence of this I have introduced a bug by changing the naming of a function parameter, which reflected through the service layer and the SDK. This meant that consumers of the API suddenly experienced a breaking change.</p> <p>Nevertheless, the main problem stems from the design. The way the proxy object works in the SDK is that it does not contain any data. This means if for instance you access the name property of a customer object you will end up going over the wire to retrieve this data. Obviously, this leads to extremely chatty behaviour by the consumers of the SDK and eventhough it is possible to avoid it is not the perceived default. The main problem though is that 50 or so entities with an average of 10 properties leads to 50*10*2 (both get and set) = 1000 methods on the service layer to implement the proxy object (could have been done with a PATCH like operation for partially updates, but alas it is not). With the standard methods for entities (create, update, delete) and some queries the API ends up having approximately 1500 public methods.</p> <p>I have removed the code generation completely and changed every method to be a &#8216;method as an object&#8217; implementation. Combined with the template pattern this means that there is very little redundant code. Unfortunately, it does not change the fact that we have 1500 public methods, which is a nightmare to maintain for us, and equally bad for our consumers to understand and navigate. Fans of the code generation in question would probably argue that it is only a problem to maintain, because the code generation has been removed, and they would be partially right. But, taking into account the number of bugs in the code generation and the number of well hidden side effects I am very happy we got rid of it.</p> <blockquote>  <p><em>When a design decision leaves you with 1500 different methods on a public API, you should really consider whether this design is a good idea</em></p></blockquote> <h4>AOP Support</h4> <p>This last example is actually one I designed myself. In a relatively simple ASP.NET MVC application we use attributes to implement AOP support using PostSharp. This actually works very well as PostSharp has a fairly straightforward API and there is no side effect by changing the code (all is handled by annotating with attributes).</p> <p>It is used for a number of things:</p> <ul><li>checking function parameters for null</li><li>checking function parameters for certain values</li><li>checking security rights on controller actions</li></ul> <p>I am not sure I would implement it this way again. The addition of the PostSharp tool does add a level of complexity and the fact that it must be installed on each and every developer machine also makes it a pricy dependency.</p> <p>Alternatively, each controller action could have been implemented as a &#8216;method as an object&#8217; and used template pattern to achieve similar results. Or maybe just do it by hand, it is not like the size of the application made it that much work. Basically, it probably is an example of overengineering that I am responsible for. </p> <h3>Challenges</h3> <p>There are a number of general challenges with using code generation:</p> <ul><li>It makes the system inherently a lot more complex.</li><li>It reduces readability quite a bit.</li><li>It makes it hard to implement business logic. The required features will be hard to determine up front, and thus the code generator will not correctly accomodate them. This leads to hacks to work around the code generator.</li><li>The APIs in .NET that are often used for this really sucks. If you really want to create code that is very hard to read, just combine CodeDOM code generation with the reflection API.</li></ul> <p>There are a some challenges that will get harder without code generation. What if you have 1500 command classes that needs to be changed? Depending on the change it could be put in a base class (if one is available), but if this is not possible it will be a harder challenge. </p> <p>How do you change 1500 classes by hand? One option is hiring a lot of very cheap labour to do it for you, but more constructively it is also feasible to create a script that does the modification and is then thrown away, which was how they were generated in the first place.</p> <blockquote>  <p><em>I have yet to see a really good example of code generation. Even those provided by visual studio, the RAILS framework, or similar, are at best minor convenience functionality.</em></p></blockquote></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/02/getting-started-with-go/">Getting Started With Go</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-02T16:08:00+02:00" pubdate data-updated="true">May 2<span>nd</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<br />In late 2007 Google started an open source initiative to develop a new programming language named Go. The goal of the language was to make it as efficient as statically compiled languages, but as easy to use as dynamic languages<br /><br />Furthermore, the language aims to solve the challenges of concurrent programming in an intuitive way. This makes a lot of sense as computers are getting more and more CPUs with more and more cores. A lot of current programming initiatives are actually focused on enabling us to easier write concurrent programs.<br /><br />Node as an example does have some tools for concurrent programs, but its main focus by using the event loop is actually an approach of strictly single threaded programming, instead focusing on reducing the blocking IO. There has been a lot of discussions going around with people claiming this approach to be either ingenious or insane. My personal experience is that it is possible to write very efficient servers in Node working with the single threaded model.<br /><br />In contrast to Node, Microsoft released the async and await keywords in C# that makes implementing asynchronous code in C# a lot easier - simply by taking away most of the work of writing such code, but it does not change how the programming model works.<br /><br />As a language Go is mostly related to the C family of languages in my opinion. Both with regards to features and syntax it more or less feels like a cleaned up version of JAVA or C# with some cruft removed and some parts made explicit that is implicit in those language. Not surprisingly Go seems to go in the opposite direction of Node (like most languages do) and has a concurrent model at the forefront of the language focus. The intriguing thing is that Go manages to this in a fairly elegant way.<br /><br />What Go promises is speed close to that of C and C++, a slim and elegant language that is as easy to use as Node (it is as easy to get a simple http server running), and powerful features for doing concurrent programming.<br /><div><br /></div><div><h3>Initial thoughts</h3><div>With my usual curiosity I have followed the development of the language from the sideline for a while, but when I saw a very impressive demonstration of building a chat server in Go at the Oredev conference last year I decided I had to take a closer look and do some development on my own. This is my initial experiments with it and thoughts about the language.</div><div><br /></div><div>Like I mentioned above the language feels like a slim and more elegant version of the languages in the C family. This meant it was fairly easy for me to get started and following the great online tutorial (<a href="http://tour.golang.org/#1">http://tour.golang.org/#1</a>) I was quickly able to produce code.</div></div><div><br /></div><h4>Clean Code</h4><div><div>I cannot recall how many hours I have wasted looking at code where half of the lines are pure cruft. Functions that are never called, variables that are never used, and so forth. Therefore, I am really excited about the way the Go compiler handles this.</div><div><br /></div><div>To illustrate this we can do a very small example. I will not go over the details (read that tutorial!), but the key is that 2 integers &#8216;a&#8217; and &#8216;b&#8217; are declared and assigned.</div><div><br /></div><div><pre>package main<br /><br />import (<br />  "fmt"<br />)<br /><br />func main() {<br />  a := 1<br />  b := 2<br />  fmt.Println(a)<br />}<br /></pre><br /></div><div>This example will simply not compile! The integer &#8216;b&#8217; is never used for anything and thus should be removed. The following will compile:</div><div><br /></div><div><pre>package main<br /><br />import (<br />  "fmt"<br />)<br /><br />func main() {<br />  a := 1<br />  fmt.Println(a)<br />}<br /></pre><br /></div><div>I have seen some people argue that this is actually annoying when you are experimenting with the code as stuff might not get used in the beginning while developing and it then has to be commented out. I believe the pros clearly outweighs the cons:</div><div><br /><ul><li>The production code is cleaner.</li><li>It seems to me that if you are adding code that is not used yet and compiling you might be in a YAGNI situation? Do not write the code until you need it.</li><li>The workaround is dead simple - just comment it out. Then if it turns out you are not going to need it someone will eventually delete that comment.&nbsp;</li></ul></div></div><br /><h4>Interfaces</h4>Go does not have classes. It has structs and functions can be added to them. As such there is no inheritance, which means as a language Go favors composition over inheritance since the later is not even possible. I really like this design as composition is to be preferred over inheritance in most scenarios in my opinion (99%?) even in a language that support inheritance. This also means that the way interfaces are implemented are different from for instance C#.<br /><br />Interfaces are implemented implicitly, which in my mind almost feels like duke typing (except checked at compile time). Thus, if an object satisfies an interface (has the required functions) it will compile. This means that interfaces can easily be added for existing code even the main library.<br /><br />Imagine what I could have done with ASP.Net HttpContext if it worked this way in C# (check my last blog post). Invent a new interface matching the few bits of HttpContext that was being used and simply pass HttpContext along. A lot more elegant that what can be done in C#.<br /><br /><br /><h4>Http Server</h4>To be honest I have not yet worked very much with Go as an Http Server, but since it is one of the things I usually end up using extensively in a language I thought I would include an example anyways.<br /><pre><br />package main<br /><br />import (<br />    "fmt"<br />    "net/http"<br />)<br /><br />type User struct {<br />    Name string<br />    Password string<br />    FavoriteColor string<br />}<br /><br />func (u User) ServeHTTP(w http.ResponseWriter, r *http.Request) {<br />    fmt.Fprintf(w, "%s, %s, %s", u.Name, u.Password, u.FavoriteColor)<br />}<br /><br />func main() { <br />    http.Handle("/user", &User{"MyUserName", "OhSoSecret", "green"})<br />    http.ListenAndServe("localhost:4000", nil)<br />}<br /></pre>I do not think that is too bad. Almost simpler than doing the same in Node, but still to early for me to say how easy it will be to implement a realistic server. <br /><br /><br /><h4>Concurrency</h4>One of the most important features of Go is the way you write concurrent code. It consists of 2 main components being goroutines and channels. A goroutine is a lightweight thread and a channel is a way to communicate between threads. </br><br />A fairly common scenario will be goroutine(s) doing some calculation (or reading data) and another goroutine that then does some further manipulation like in this example.  <pre><br />package main<br /><br />import (<br />  "fmt"<br />)<br /><br />func getdata(resCh chan<- int) {<br />  i := 0<br />  for {<br />    resCh <- i  <br />    i++         <br />  }<br />}<br /><br />func printer(resCh <-chan int) {<br />  for {<br />    res := <- resCh  <br />    fmt.Println(res)         <br />  }<br />}<br /><br />func main() {<br />  resCh := make(chan int, 100)<br />    <br />  go getdata(resCh)<br />  go printer(resCh)<br /><br />  var input string<br />  fmt.Scanln(&input)<br />}<br /></pre>A dumb example I agree, as there are easier ways of printing sequential integers to the console. The point was to showcase the way functions can be started in goroutines and use channels to communicate. <br /><br />I find this a quite elegant way of doing concurrent programming, and if you want to see a slightly less contrived example take the tutorial of Go and solve the last exercise (you can find mine at my github account: <a href="https://github.com/elgsdyret/go_playground/blob/master/fetcher_2.go">https://github.com/elgsdyret/go_playground/blob/master/fetcher_2.go</a>).  </br></br></br><h4>Wrap Up</h4> With the limited experiments I have done so far I think Go has a lot going for it. Which is also why more and more companies are showing of stuff implemented in Go. For instance Mozilla just released a beta on Heka, a quite interesting project, which is written in Go (<a href="http://blog.mozilla.org/services/2013/04/30/introducing-heka/">http://blog.mozilla.org/services/2013/04/30/introducing-heka/</a>). </br></br>Next step is to play around with more areas of Go. How to write unit tests? How hard is it to write more advanced web servers?     </div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/22/working-effectively-with-aspnet-and/">Working Effectively With ASP.NET and HttpContext</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-22T19:15:00+02:00" pubdate data-updated="true">Apr 22<span>nd</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
Often in an ASP.NET WebForms application you will get up with unmanageable depencencies on the ASP.NET web stack expressed through the HttpContext class.<br /><br />This often appears in the form of code like this:<br /><script class="brush: c#" type="syntaxhighlighter"><![CDATA[public void DoSomeCoreStuff()  {    var userId = (string)HttpContext.Current.Session["userId"];    DoSomeMoreCoreStuff(userId); }]]></script> This code could be located anywhere in you codebase, and I have seen examples of such calls to session being done more or less inline in a string describing an SQL query. It does not necessarily have to be the Session property that is accessed though, the problem is the same if Application or other bits of the current http context is accessed this way.<br /><br />There is a number of problems with this approach.<br /><ul><li>Using a string like this is not strongly typed, which easily leads to errors. For instance the session variables might have had a different casing like &#8220;CurrentUserId&#8221;.</li><li>A static reference to HttpContext.Current causes a number of problems. Firstly, it will be hard to use the code in question outside the ASP.NET stack, and secondly it will be equally hard to write meaningful tests for the code in questions.</li></ul><br /><h3>Options</h3>There are a number of ways to solve this problem leading to a much cleaner design enabling testing and reuse. All the options involves pushing the actual call to HttpContext.Current as far up in the call chain as possible, meaning in the code behind of the aspx page.<br /><br /><h4>Simple Types</h4>Given that the currentUserId in our example above is an string (or any other simple type or object that can be easily constructed) why not just use that? It can be injected through the constructor or the method in question.<br /><script class="brush: c#" type="syntaxhighlighter"><![CDATA[public void DoSomeCoreStuff(string userId)  {    DoSomeMoreCoreStuff(userId); }]]></script> <br /><br /><h4>Domain Specific Wrapper Class&nbsp;</h4>Often it is not as simple as a single entry that you want to retrieve from the session. Maybe there is a group of related entries that you want to use.<br /><script class="brush: c#" type="syntaxhighlighter"><![CDATA[public void DoSomeCoreStuff() {   var userId = (string)HttpContext.Current.Session["currentUserId"];   var userColor = (string)HttpContext.Current.Session["favoriteColor"];   var userNickname = (string)HttpContext.Current.Session["nick"];   DoSomeMoreCoreStuff(userId, userColor, userNickname); }]]></script> In that case an interface named according to the relation (for instance UserContext in our example) and injected can solve this problem. The key is to have an implementation of the interface that actually wraps Session and ensure that the string key for the entry is not copied all over the code. The wrapper implementation is instantiated at the top level of the web stack, most often in the code behind class and elsewhere we code against the interface in a inversion of control style.<br /><script class="brush: c#" type="syntaxhighlighter"><![CDATA[public void DoSomeCoreStuff(UserContext userContext) {   var userId = userContext.Id;   var userColor = userContext.FavoriteColor;   var userNickname = userContext.NickName;   DoSomeMoreCoreStuff(userId, userColor, userNickname); }]]></script> The implementation of the interface looks something like this: <br /><script class="brush: c#" type="syntaxhighlighter"><![CDATA[public class HttpContextUserContext : UserContext {   HttpContext context;    public HttpContextUserContext(HttpContext context)   {     this.context = context;   }    public string Id   {     get     {       return (string)context.Session["currentUserId"];     }   }    public string FavoriteColor   {     get     {       return (string)context.Session["favoriteColor"];     }   }    public string NickName   {     get     {       return (string)context.Session["nick"];     }   } }]]></script> It might seem like a lot of code, but the flexibility is definitely worth the small overhead of adding this. <br /><h4></h4><h4>HttpContextBase</h4><div><br /></div>The main problem with the original implementation of the HttpContext class is that it is not based on an interface nor an abstract base class. This means that reusing code that depends on HttpContext can be hard, and testing equally hard. Microsoft realized this problen when they released the MVC framework and added a class called HttpContextBase. The funny thing is that HttpContext does not inherit from HttpContextBase as that would be a breaking change, but it has the exact same API.<br /><br />Thus, our problem from above with the static dependency could be solved as the following stepwise refactoring:<br /><br /><ul><li>Ensure that HttpContext is injected through the constructor or the method in question and ensure that HttpContext.Current is passed in as that value.</li><li>Replace HttpContext in the constructor or method with HttpContextBase and replace HttpContext.Current with new HttpContextWrapper(HttpContext.Current)</li></ul>And our example would then look something like this: <br /><script class="brush: c#" type="syntaxhighlighter"><![CDATA[public void DoSomeCoreStuff(HttpContextBase context)  {    var userId = (string)context.Session["userId"];    DoSomeMoreCoreStuff(userId); }]]></script>This might seem a bit overkill, but we are now able to use our method with a different implementation of HttpContextBase for reuse and testing purposes.<br /><br />When doing a different implementation you should know that every base implementation in HttpContextBase just throws a NotImplementedException. Thus, you will need to override that different bits in your test and reuse implementations depending on what you really require. Alternatively, there are a couple of generic open source implementations available if you want to pull in that extra dependency.<br /><br />In general I would recommend using one of the first approaches, but if you are working with a fairly large system that adheres to the big ball of mud &#8220;design&#8221; antipattern this might be difficult. Maybe it is just to difficult to discern any meaningful relation between the different data retrieved from HttpContext, and with this approach you can at least start writing some tests to get control back of the code.<br /><br />As I mentioned earlier this is just one simple example as HttpContext have a lot of data and functionality built in.<br /><div><br /><br /></div></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/03/24/playing-with-dynamic-keyword/">Playing With the Dynamic Keyword</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-03-24T09:28:00+01:00" pubdate data-updated="true">Mar 24<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<br /><br />I have not yet had a chance to play around with the dynamic features that was introduced with .NET 4, probably because I have yet to find a good scenario for using it and probably because I am mostly stuck on doing work on the .NET 3.5.<br /><br />Fortunately, I am currently working on a new REST API build in Nancy and the dynamic features of .NET 4 seems perfect to implement HTTP PATCH.<br /><br />Our way of thinking is that it is hard to model with traditional classes as not all properties are necessarily included. One solution could be to make them all nullable and use that, but then it would not be possible for us to distinguish between a property simply not in the body of the request and a property the consumer deliberately set to null.<br /><br />My first test was like this:<br /><br /><pre class="brush: c#">public void DynamicValueNoneSet()<br />{<br />  dynamic a = new ExpandoObject();   <br />  string name = a.Name;   <br />}<br /></pre><br />This showed me that I would get a RunTimeBinderException if a given value was not available (yes I could also have read the documentation, but how fun is that?).  <br />My next attempt included this little implementation of DynamicObject - to avoid getting the exception when using:<br /><br /><script type="syntaxhighlighter" class="brush: c#"><![CDATA[ public class NullDynamic : DynamicObject {   private readonly IDictionary<string, object> expando;    public NullDynamic()   {     expando = new ExpandoObject();   }    public override bool TryGetMember(GetMemberBinder binder, out object result)   {     expando.TryGetValue(binder.Name, out result);     return true;      }    public override bool TrySetMember(SetMemberBinder binder, object value)   {     expando[binder.Name] = value;     return true;   } }]]></script><br />Since the declared goal is to be able to distinguish between a value not being there and deliberately being set to null, this would not work either.<br />Actually what I found myself thinking was that I missed the &#8220;undefined&#8221; value from javascript, or some other way to express that something was not there, built into the language.<br /><br />Trying to avoid going to such drastic measure I came up with this: <br /><br /><script type="syntaxhighlighter" class="brush: c#"><![CDATA[ public class Dynosaur: DynamicObject {   private readonly IDictionary<string, object> expando;    public Dynosaur()   {    expando = new ExpandoObject();   }    public override bool TryGetMember(GetMemberBinder binder, out object result)   {    return expando.TryGetValue(binder.Name, out result);      }    public override bool TrySetMember(SetMemberBinder binder, object value)   {    expando[binder.Name] = value;    return true;      }    public bool HasValue(string name)   {    return expando.Keys.Contains(name);   } } }]]></script><br />Maybe no the most elegant solution, but I does allow me to write code like: <br /><br /><pre class="brush: c#">public void PrintName(dynamic a)<br />{<br />  if (!a.HasValue("Name"))<br />  {<br />    a.Name = "dog";<br />  }<br />  Console.WriteLine("the name is: " + a.Name);<br />}<br /></pre><br />Given that &#8220;a&#8221; is actually an instance of my Dynosaur class. I would not say that I am entirely satisfied with this implementation, but I actually think that this is as far as the dynamic features of C# will take me.<br /><br />Any good ideas out there? I am thinking there must be other people that has played around with this and has come up some crazy dynamic stuff in C#.<br /><br /><br /></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/03/16/devops-days-london-2013/">DevOps Days London 2013</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-03-16T21:38:00+01:00" pubdate data-updated="true">Mar 16<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<br /><br />The devops &#8220;thingy&#8221; is only a few years old. I use the word &#8220;thingy&#8221; (if it can be considered a word) as it is seemingly hard to describe precisely what exactly devops is.<br /><br />I am new to devops, but went to devops days in London anyways. This is my attempt to clear my head of some of the thoughts, ideas, and impressions that have been rambling around my head for these two days, and probably will for quite some time.<br /><br />I had a blast of a time in London listening to the different speakers and participating in discussions, but I must admit that I am even more confused now than I was before coming. Nevertheless, I did get some impressions:<br /><br />1.) Getting back to my opening sentence, the notion that has struck me as being one of the most important is that devops might not be meant to be described precisely, but is a continuous movement towards a better way of delivering value for the end customer (ups&#8230; I just did my own attempt at a description).<br /><br />I have heard several other suggestions during these days and it seems that each individual has his own definition of devops. I had the pleasure of talking with Patrick Debois over a beer about this and he hinted that this was actually on purpose. Maybe the journey is more important than the goal and a large part of the value comes from defining what devops means to you? What is your definition?<br /><br />2.) You can get some value with tools and processes, but if you do not get the people aboard you will not get to the end goal (which seems to be as hard to define as the definition).<br /><br />3.) Changing culture seems to be most powerful pattern for doing devops and maybe the only really relevant one.<br /><br />4.) There are a zillion of tools out there that I had never heard about and I am going to try out. Seems like everybody is using (have used at some point) logstash, graphite and so forth.<br /><br />5.) The people that do devops are awesome and passionate about it, which makes me want to learn more and participate in more devops days (Copenhagen next year anyone?)<br /><br />Cheers!<br /><br /></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/11/18/polyglot-javascript/">Polyglot JavaScript</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-11-18T13:14:00+01:00" pubdate data-updated="true">Nov 18<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<br /><div>Over time&nbsp;JavaScript&nbsp;has gained a lot of traction as it is the default option for running code in the browser, and it has become a valid server option with the rise of node. This progress has largely been fueled by an arms race between the major browser vendor&nbsp;continuously&nbsp;trying to wield the fastest environment for running&nbsp;JavaScript.</div><div><br /></div><div>Thus, as&nbsp;JavaScript&nbsp;can be run everywhere and with the notion that this language like any other has its rough spots (partly due to the history of it&#8217;s creation, a notion supported by the famous book by Douglas Crockford &#8220;JavaScript the Good Parts&#8221;) it is no wonder that alternatives that compiles to&nbsp;JavaScript&nbsp;have been popping up for a while.</div><div><br /></div><div>Microsoft recently released TypeScript to join the efforts of Google with their Dart language to define the future of code running in the browser. Simultaneously, initiatives like CoffeeScript (by J Ashkenas) has gained some traction and the community is working (fighting) to get the next version of JavaScript ready. Another option that I cannot leave out is ClojureScript a version of the brilliant Clojure language that compiles to JavaScript.</div><div><br /></div><div>The options are abundant each with their own goals. Some like TypeScript and Dart aim to bring some form of static typing to the table (I do not specifically want this in JavaScript, but I still welcome these initiatives), while a language such as CoffeeScript aim to improve the syntax and hide some of the bad parts of JavaScript.</div><div><br /></div><div>J. Ashkenas (of BackBone, Underscore and CoffeeScript fame) maintains a quite comprehensive list (<a href="https://github.com/jashkenas/coffee-script/wiki/List-of-languages-that-compile-to-JS">https://github.com/jashkenas/coffee-script/wiki/List-of-languages-that-compile-to-JS</a>), and for a good read on the different aspect of languages compiling to JavaScript consider:&nbsp;<a href="http://buildnewgames.com/compiling-to-javascript/">http://buildnewgames.com/compiling-to-javascript/</a>.</div><div><br /></div><div>Indeed it is a very good time to be a web (Node) programmer. Some notable JavaScript engineers (Such as N. Zakas) claim that time would be better spent improving JavaScript and teaching it than building alternatives, but I believe that every new language will bring inspiration to developers and to the future of JavaScript.</div><div><br /></div><div>All of the languages compiling to JavaScript has a shared number of cons:</div><div><ol><li>Build process: Because they actually compile to JavaScript. Any serious JavaScript project will have a build process anyways, combining files, minifying, obfuscating, possibly running&nbsp;test suites&nbsp;automatically, and thus I do not see a big problem with this.</li><li>Debugging: Since what you are sending to the browser is JavaScript your debugging will also be in JavaScript. This means that unless you can get source map to work (<a href="http://addyosmani.com/blog/the-breakpoint-episode-3-source-maps-shortcut-secrets-and-jsrun/">http://addyosmani.com/blog/the-breakpoint-episode-3-source-maps-shortcut-secrets-and-jsrun/</a>)&nbsp;, to use one of these languages you need to be fluent in JavaScript.&nbsp;Definitely&nbsp; a challenge for some, but for experienced JavaScript developers this might not be a big problem (on a&nbsp;side note&nbsp;I believe that CoffeeScript for instance generates quite nice JavaScript).</li></ol></div><h3><br />CoffeeScript</h3><div>I have spend some energy on CoffeeScript as an alternative (or in addition to!) to JavaScript on my projects. I believe CoffeeScript brings readability and as a consequence of this also maintainability to a project. I cannot stress enough how important readability is for any piece of code and as such doing CoffeeScript to improve that becomes a very intriguing option.</div><div><br />One of the features about CoffeeScript that i most often hear complaints against is meaningful indentation, and it was also something I personally was not sure I would like. Nevertheless, the more I think about it, I am for using the indentation, as this is the way I consume code more than it is the braces. Why should the compiler use a different mechanism than me for interpreting code? Is it not easier to maintain code where your understand the code the same way the compiler does?<br /><br />Here is just a few examples of features I believe adds&nbsp;readability&nbsp;to code:<br /><br /></div><div>Function syntax:<br /><pre class="brush: javascript">var a = function() { return x*x; };</pre>becomes: <br /><pre class="brush: coffeescript">a = -&gt; x*x</pre><br />This especially becomes valuable if you like me use a lot of underscore.js functionality:<br /><pre class="brush: javascript">_([1, 2, 3]).each(function(num){ alert(num); });</pre>becomes: <br /><pre class="brush: coffeescript">_([1, 2, 3]).each((num) -&gt; alert(num));</pre><br />Default values.<br /><pre class="brush: javascript">function(a, b) { <br />   if (!b) { <br />     b = 'b'; <br />   } <br />   console.log(a, b); <br />}<br /></pre><br />In CoffeeScript you could do: <br /><pre class="brush: coffeescript">(a, b = 'b') -&gt; console.log(a, b)</pre><br />Basically, CoffeeScript is full of features that reduces the cluttering of your code removing unnecessary noise and thereby improving readability.<br /><br />I could whip up a ton more examples, but instead if will just point you to&nbsp;<a href="http://coffeescript.org/">http://coffeescript.org/</a>&nbsp;where you can read more if your interested. No need for me to copying all the examples :-D<br /><br />Recently, I converted a JavaScript project to CoffeeScript and I litterally ended up removing one third of all the characters just in the conversion. Afterwards, I spends some time using some of the nice features such as default values for parameters and splats, and consequently was able to reduce the amount of code even more.<br /><br />It is indeed a good time to be a polyglot JavaScript developer and I cheer&nbsp;every single time&nbsp;a new language can compile to JavaScript - bring it on!<br /><br /><br /></div><div><br /></div></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/09/11/cors-vs-aspnet-session/">CORS vs ASP.NET Session</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-09-11T20:02:00+02:00" pubdate data-updated="true">Sep 11<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<br />The last couple of days I have been trying to implement a pure javascript client that could connect to our SOAP API. <br /><br />To do that we need to enable <a href="http://en.wikipedia.org/wiki/Cross-origin_resource_sharing">Cross-origin resource sharing</a> (called CORS for short). Basically, as a security measure browsers implement Same origin policy ensuring that only programs loaded from the same domain can query resources on that domain.<br /><br />Thus, a javascript loaded from http://www.example.com/myprogram.html could query http://www.example.com/api, but no http://www.test.com/api.<br /><br />As Rich Internet Applications written as javascript clients is seeing an increase in popularity (and ease of implementing due to lots of nice frameworks such as Backbone), more and more providers of services will want to expose those services directly to the clients.<br /><br />To enable CORS we need to set a series of headers and respond to the HTTP OPTIONS verb request (used by the browser to figure out if the server actually supports CORS). To be honest I have yet to figure out all the headers and exactly why each one is required, but with some trial and error I have gotten it to work.<br /><br /><br /><h4>Allowing CORS from ASP.NET SOAP WebService</h4>The first challenge for our API was to get our ASP.NET SOAP service to set the correct headers (which I just admitted to not knowing&#8230;) for only that service.<br /><br />It turned out this is actually not that hard and throwing in a HttpModule setting the headers for requests to a specific url (the service) with a lot of random (more or less) headers actually enabled me to invoke the service from javascript.<br /><br /><pre class="brush: c#">public void AddCors(HttpApplication httpApplication)<br />{<br />  var sb = new StringBuilder();<br />  var hdrs = httpApplication.Response.Headers;<br />  var origin = hdrs.Get("Origin");<br />  if (string.IsNullOrEmpty(origin))<br />  {<br />    origin = "*";<br />  }<br />  hdrs.Add("Access-Control-Allow-Origin", origin);<br />  hdrs.Add("Access-Control-Allow-Credentials", "true");<br />  sb.Append("Content-Type, Cake");<br />  if (httpApplication.Request.HttpMethod.ToUpper() != "OPTIONS")<br />  {<br />    hdrs.Add("Access-Control-Allow-Headers", sb.ToString());<br />    return;<br />  }<br />  hdrs.Add("Access-Control-Allow-Methods",<br />"GET,POST,PUT,DELETE,OPTIONS");   <br />  // TODO: how many of these do we need???<br />  sb.Append(",authorization,Content-Type,accept");<br />  sb.Append(",accept-charset,accept-encoding,accept-language");<br />  sb.Append(",connection,content-length,content-type");<br />  sb.Append(",host,origin,referer,user-agent, SOAPAction");<br />  hdrs.Add("Access-Control-Allow-Headers", sb.ToString());    <br />  hdrs.Add("Access-Control-Max-Age", "3000"); //seconds<br />  hdrs.Add("content-length", "0");<br />  httpApplication.Response.StatusCode = 204;<br />}<br /></pre><br /><br /><h4>Consuming SOAP envelopes from JavaScript</h4>I tried out a number of promising leads for consuming SOAP services. The common ground for all of them was that they used the XmlHttpRequest object internally and tried to generate a proxy based on the wsdl of the service. After a couple of tries I gave up on this approach and went closer to the metal.<br /><br />Using fiddler and an integration that worked (written as a server) I spied on the SOAP envelopes needed to send the requests, and saved them as templates (in the format for Mustache.js). This way I could easily put in the values needed without having to worry about serializing object and manipulating XML. The response was simply parsed using regex&#8217; and thus I was able to handle the envelopes.<br /><br />Actually, this way of handling although primitive is not half bad. If the service changes the service contract the template/regex has to be updated, but code generated on top of the wsdl would suffer from the same, and the implementation is extremely simple and basic this way.<br /><br />The last bit was sending the requests to the server which was done through jQuery and the XmlHttpRequest. This took me some fiddling (not using fiddler) and googling to find the exact parameters and such. Again I used fiddler to find the correct headers for the requests and added them using jQuery.<br /><br /><h4>Using ASP.NET Cookie SessionState from JavaScript</h4><div>Thus, I was able to log in to our web service and retrieve the key used for subsequent request as an access token (actually the ASP.NET session id).<br /><br />Unfortunately, the web service uses ASP.NET session to maintain whether you are logged in or not. Thus, a Set-Cookie header is returned from the Connect method and that Cookie must be returned in the header of the following requests to ensure access.<br /><br />Due to security measures it is not possible to add the Cookie header manually to the XmlHttpRequest object. As the session id is also returned in the SOAP response envelope it is not a problem to retrieve it and I managed it to send it in another header called CAKE (part of the explanation for the many weird headers in the CORS implementation above).<br /><br />Thus, I was stuck with changing the service implementation (not relying on ASP.NET session or somehow hijacking it using my CAKE header) or forcing the potential consumers of our API to use one of the potential hacks using iframes or JSONP (which I have not tested), but at least the last option defeats the purpose of making it easy to access (one could ago that SOAP does the same, but that is another battle).<br /><br />What is the point you might ask? I actually managed to implement CORS, but due to the implementation using ASP.NET Session it is completely useless.<br /><br />Anyone has any hacks worth trying?<br /><br />&nbsp;Next step&#8230;. Something more usable than SOAP&#8230;&#8230;. Not using ASP.NET Session<br /><br /><br /><br /><br /><br /><br /></div><br /></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/09/08/maintainable-aspnet-webforms-part-ii/">Maintainable ASP.NET Webforms - Part II</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-09-08T13:36:00+02:00" pubdate data-updated="true">Sep 8<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<br /><br />In the last post I described how I believe that implementing the MVP pattern is a feasible way of improving ASP.NET Web Forms code:<br /><br /><a href="http://nikolajkn.blogspot.dk/2012/09/maintainable-aspnet-webforms-part-i.html">http://nikolajkn.blogspot.dk/2012/09/maintainable-aspnet-webforms-part-i.html</a><br /><br />The most important lesson is still that you should not use ASP.NET Web Forms unless you absolutely have to.<br /><br /><h4>The Example</h4>I have added a tiny example to github:&nbsp;<a href="https://github.com/elgsdyret/mvp-example">https://github.com/elgsdyret/mvp-example</a><br /><br />Like any contrived example it might be too simple and too silly to really show the power of implementing the pages this way, but here is a short walk-through of the flow anyways:<br />The view loads the presenter with a reference to itself and asks it to PresentAllDogs: <pre class="brush: c#">protected void Page_Load(object sender, EventArgs e)<br />{<br /> presenter = new DogSearchPresenter(this);<br /> presenter.PresentAllDogs();<br />}<br /></pre> The presenter then retrieves all the dogs (probably from some kind of data layer) and asks the view to render the dogs:  <pre class="brush: c#">public void PresentAllDogs()<br />{<br /> view.RenderDogs(Dog.All());<br />}<br /></pre> The view just assigns a local field with the values retrived (in some scenarios it might be doing a databind or similar, all depending on how the template aspx is used):  <script type="syntaxhighlighter" class="brush: c#"><![CDATA[ public void RenderDogs(IList<Dog> dogs) {  Dogs = dogs; } ]]></script> When the template is rendered it automatically renders the Dogs from the view:  <script type="syntaxhighlighter" class="brush: c#"><table> <tr><th>Name</th><th>Race</th></tr> <%foreach(var dog in Dogs)    { %>  <tr>   <td><%=dog.Name%></td>   <td><%=dog.Race%></td>  </tr>     <% } %></table></script> This way of rendering is my preferred as it puts just the right amount of rendering logic in the template. It does not work well if you need to manipulate specific rows of the table and have the viewstate handle which you clicked.  <br/><br/>For this you could use the listview control which is a decent compromise between using raw template rendering and having the view set values on elements using the runat server tag (I definetely prefer the first template rendering.)  <br/><br/>Happy coding!    </div>
<h2>Comments</h2>
<div class='comments'>
<div class='comment'>
<div class='author'>Alexander Beletsky</div>
<div class='content'>
Good stuff.<br /><br />There is ASP.NET MVP framework. <br /><br />http://aspnetmvp.codeplex.com/<br /><br />But I also still prefer lightweight custom solutions.</div>
</div>
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/09/08/maintainable-aspnet-webforms-part-i/">Maintainable ASP.NET Webforms - Part I</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-09-08T11:04:00+02:00" pubdate data-updated="true">Sep 8<span>th</span>, 2012</time>
        
      </p>
    
  </header>


  <div class="entry-content"><div class='post'>
<br /><br /><br />In the next couple of blog posts I will try to outline how I try to improve the maintainability and testability of pages written in the ASP.NET Web Forms framework.<br /><br /><h3>Don&#8217;t use ASP.NET Web Forms</h3><div>If you are not forced there is no good reason to use this technology. There are many better ways to write your web applications. If you wish to work with the .NET framework you might consider:</div><div><ul><li>ASP.NET MVC latest incarnation (if it just has to be Microsoft)</li><li>Nancy (nice open source framework)</li><li>&#8230; and other options</li></ul><div>If your wish to use something other than .NET there are also many options (the reason I base this decision on whether you want .NET or not is simply because we started out discussing alternatives to Web Forms):</div></div><div><ul><li>&nbsp;RAILS, Sinatra, Goliath and other options on Ruby.</li><li>Django on Python.</li><li>Node.js potentially with the express framework.</li><li>&#8230; and lots of other options.</li></ul><div>Point is: <b>First way to improve your Web (Forms) code is to not use Web Forms.</b></div></div><div><br /></div><h3>I Have no Choice</h3><div>If you are stuck building Web Forms, it is most likely due to working on a legacy system build with this technology. There are lots of those out there and they are not getting upgraded to better options (at least not all of them).</div><div><br /></div><div>Thus, we have to manage somehow.</div><div><br /></div><div>The main tactic I advocate for coping with the platform is a pattern called MVP (Model-View-Presenter):</div><div><br /></div><div><a href="http://martinfowler.com/eaaDev/uiArchs.html">http://martinfowler.com/eaaDev/uiArchs.html</a></div><div><br /></div><div>(Go down a bit to find the description)</div><div><br /></div><div>Now this may not be the most easily accessible description and potentially you might not be able to implement the pattern in your application from this description (or it would require quite some work).</div><div><br />There is a catch to the pattern though. If used correctly it can help make your code more testable and easier to reason about, but it adds complexity and will not save you from having to know about viewstate, page lifecycle and other details about Web Forms.</div><h3>Bits and Pieces</h3><div>Not&nbsp;surprisingly&nbsp;we need a class for each of the roles of Model, View, and Presenter (actually a bit more).</div><div><br /></div><h4>Model&nbsp;</h4><div>The model is just a PONO (plain old .NET object) and can be your domain model or alternatively a view model. When to use a view model is largely a matter of taste, but I prefer not to do it unless I actually use it for something as it does add an overhead of an extra class and mapping code (consider using a tool like automapper if you do have both models).</div><div><br /></div><h4>View</h4><div>The view in our ASP.NET webform MVP implementation is basically our code behind file and the aspx file can be considered a template for helping with rendering the html. The key is to keep the code behind file very very slim as the view can typically be very hard to test due to dependencies on ASP.NET.<br /><br />The responsibility of the view is to render html, retrieve values from the html (really being the viewstate), and kicking of the flow (that is the way webforms work).<br /><br />The view is hidden by an interface to save the Presenter from knowing the gritty details of webforms. This way the presenter could also be used in another application that is not necessarily for the web.</div><div><br />The view initializes the presenter with a reference to itself - typically in the pageload event, but that really depends on the purpose of the page.</div><div><h4>Presenter</h4></div><div>The presenter is somewhat similar to the Controller in the MVC pattern, at least in the way I use it. It is not triggered in the same way as in MVC, though, as the view has to start it up.</div><div><br /></div><div>Basically, the presenter handles the flow of the page, receiving data from the view when an event occurs (a button is clicked for instance), using lower level constructs (like data-layers or services) to manipulate data and then typically asking the view to render something. I would never have a presenter function return a value, as it is solely up to the presenter to determine what the view should do (not how though).</div><div><br /></div><div>The presenter will get a reference to the view through the interface in the constructor.</div><div><br /></div><div>In .NET this leaves us with 5 pieces:</div><div>- A View (for instance SearchDogView) which inherits from&nbsp;System.Web.UI.Page.</div><div>- A template used for rendering html for the view (the ASPX file).</div><div>- An interface for the view (ISearchDogView).</div><div>- A presenter (SearchDogPresenter)</div><div>- A model (or 2 if we decide to use a ViewModel)</div><div><br /></div><div><br /></div><div><a href="http://nikolajkn.blogspot.dk/2012/09/maintainable-aspnet-webforms-part-ii.html"> Part II: A tiny example </a></div><div><br /></div><div><br /></div><div><br /></div><div></div><div><br /></div><div><br /></div></div>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/05/27/porting-to-octopress/">Porting to Octopress</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/25/code-generation-in-net/">Code Generation in .NET</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/02/getting-started-with-go/">Getting Started With Go</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/22/working-effectively-with-aspnet-and/">Working Effectively With ASP.NET and HttpContext</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/03/24/playing-with-dynamic-keyword/">Playing With the Dynamic Keyword</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/elgsdyret">@elgsdyret</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'elgsdyret',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Nikolaj Kaare NÃ¸rskov -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
